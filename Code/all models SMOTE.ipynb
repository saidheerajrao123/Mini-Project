{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc32a92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DecisionTree_SMOTE Evaluation ===\n",
      "Best Threshold: 1.0000\n",
      "Accuracy: 0.9921\n",
      "Precision: 0.4050\n",
      "Recall: 0.7615\n",
      "Specificity: 0.9935\n",
      "ROC AUC: 0.8775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    257834\n",
      "           1       0.41      0.76      0.53      1501\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.70      0.88      0.76    259335\n",
      "weighted avg       1.00      0.99      0.99    259335\n",
      "\n",
      "\n",
      "=== RandomForest_SMOTE Evaluation ===\n",
      "Best Threshold: 0.7400\n",
      "Accuracy: 0.9971\n",
      "Precision: 0.7812\n",
      "Recall: 0.6995\n",
      "Specificity: 0.9989\n",
      "ROC AUC: 0.9874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.78      0.70      0.74      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.89      0.85      0.87    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "=== LogisticRegression_SMOTE Evaluation ===\n",
      "Best Threshold: 0.5029\n",
      "Accuracy: 0.8752\n",
      "Precision: 0.0066\n",
      "Recall: 0.1366\n",
      "Specificity: 0.8795\n",
      "ROC AUC: 0.5041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93    257834\n",
      "           1       0.01      0.14      0.01      1501\n",
      "\n",
      "    accuracy                           0.88    259335\n",
      "   macro avg       0.50      0.51      0.47    259335\n",
      "weighted avg       0.99      0.88      0.93    259335\n",
      "\n",
      "\n",
      "=== ExtraTrees_SMOTE Evaluation ===\n",
      "Best Threshold: 0.6500\n",
      "Accuracy: 0.9971\n",
      "Precision: 0.7681\n",
      "Recall: 0.7062\n",
      "Specificity: 0.9988\n",
      "ROC AUC: 0.9860\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.77      0.71      0.74      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.88      0.85      0.87    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === 1. Import Required Libraries ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, precision_recall_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE  # âœ… Changed here\n",
    "import joblib\n",
    "\n",
    "# === 2. Load Dataset ===\n",
    "df = pd.read_csv(\"D:/MTech/Mini project/archive (9)/fraudTrain.csv\")\n",
    "\n",
    "# === 3. Feature Engineering ===\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['hour'] = df['trans_date_trans_time'].dt.hour\n",
    "df['is_night'] = df['hour'].apply(lambda x: 1 if x <= 6 else 0)\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['age'] = df['trans_date_trans_time'].dt.year - df['dob'].dt.year\n",
    "df['log_amt'] = np.clip(np.log1p(df['amt']), a_min=None, a_max=7)\n",
    "df['amt_to_pop_ratio'] = df['amt'] / (df['city_pop'] + 1)\n",
    "df['amt_hour_ratio'] = df['log_amt'] / (df['hour'] + 1)\n",
    "df['pop_amt_ratio'] = df['log_amt'] / (df['city_pop'] + 1)\n",
    "df['merchant_avg_amt'] = df.groupby('merchant')['amt'].transform('mean')\n",
    "df['amt_to_merchant_avg'] = df['amt'] / (df['merchant_avg_amt'] + 1)\n",
    "\n",
    "# === 4. Encode Categorical Features ===\n",
    "categorical_cols = ['category', 'merchant', 'job']\n",
    "encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "# === 5. Select Features ===\n",
    "selected_features = [\n",
    "    'log_amt', 'category', 'merchant', 'hour', 'is_night',\n",
    "    'city_pop', 'lat', 'long', 'merch_lat', 'merch_long',\n",
    "    'job', 'amt_to_pop_ratio', 'amt_hour_ratio', 'pop_amt_ratio',\n",
    "    'amt_to_merchant_avg'\n",
    "]\n",
    "\n",
    "X = df[selected_features]\n",
    "y = df['is_fraud']\n",
    "\n",
    "# === 6. Train-Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# === 7. Oversampling using SMOTE ===\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# === 8. Define Models ===\n",
    "models = {\n",
    "    \"DecisionTree_SMOTE\": DecisionTreeClassifier(random_state=42),\n",
    "    \"RandomForest_SMOTE\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"LogisticRegression_SMOTE\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"ExtraTrees_SMOTE\": ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# === 9. Train and Evaluate Each Model ===\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_bal, y_train_bal)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "    best_index = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_index]\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n=== {name} Evaluation ===\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    print(f\"Best Threshold: {best_threshold:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Optional: Save each model separately\n",
    "    joblib.dump(model, f\"{name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1acfaac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š DecisionTree_SMOTE â€” MCC: 0.5520\n",
      "\n",
      "ðŸ“Š RandomForest_SMOTE â€” MCC: 0.7378\n",
      "\n",
      "ðŸ“Š LogisticRegression_SMOTE â€” MCC: 0.0037\n",
      "\n",
      "ðŸ“Š ExtraTrees_SMOTE â€” MCC: 0.7350\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from math import sqrt\n",
    "\n",
    "# === Load test set ===\n",
    "# If needed, reload test data from earlier steps\n",
    "# Assuming X_test and y_test already available in memory\n",
    "\n",
    "# === List of model names (same as saved filenames) ===\n",
    "model_names = [\n",
    "    \"DecisionTree_SMOTE\",\n",
    "    \"RandomForest_SMOTE\",\n",
    "    \"LogisticRegression_SMOTE\",\n",
    "    \"ExtraTrees_SMOTE\"\n",
    "]\n",
    "\n",
    "for name in model_names:\n",
    "    model = joblib.load(f\"{name}.pkl\")\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Find threshold by F1 or reuse a standard value like 0.5\n",
    "    # Or reuse threshold value stored previously, e.g., best_threshold = 0.9648\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "    best_index = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_index]\n",
    "\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "    # === Confusion matrix ===\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "    # === MCC Calculation ===\n",
    "    numerator = (TP * TN) - (FP * FN)\n",
    "    denominator = sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    mcc = numerator / denominator if denominator != 0 else 0\n",
    "\n",
    "    print(f\"\\nðŸ“Š {name} â€” MCC: {mcc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800accf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
